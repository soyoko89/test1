{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wDtWZlKWG-zr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dybgHgKrcV7"
      },
      "source": [
        "##Activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "u5x61ArOHjzA"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return self.sigmoid(A)\n",
        "    def backward(self, dZ):\n",
        "        _sig = self.sigmoid(self.A)\n",
        "        return dZ * (1 - _sig)*_sig\n",
        "    def sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "\n",
        "class Tanh:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.tanh(A)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * (1 - (np.tanh(self.A))**2)\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
        "        return self.Z\n",
        "    def backward(self, Y):\n",
        "        self.loss = self.loss_func(Y)\n",
        "        return self.Z - Y\n",
        "    def loss_func(self, Y, Z=None):\n",
        "        if Z is None:\n",
        "            Z = self.Z\n",
        "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KFGDY6Ers5u"
      },
      "source": [
        "##FC = Neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yX4vmJZ0H4LR"
      },
      "outputs": [],
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        A = X@self.W + self.B\n",
        "        return A\n",
        "    def backward(self, dA):\n",
        "        dZ = dA@self.W.T\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.X.T@dA\n",
        "        self.optimizer.update(self)\n",
        "        return dZ\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFpeAn5Fr8GO"
      },
      "source": [
        "##Defining a Weight Initialization Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Fixn97BAH8ID"
      },
      "outputs": [],
      "source": [
        "class XavierInitializer:\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = math.sqrt(1 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        return B\n",
        "    \n",
        "class HeInitializer():\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = math.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        return B\n",
        "        \n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, *shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "    def B(self, *shape):\n",
        "        B = self.sigma * np.random.randn(*shape)\n",
        "        return B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mkdEpVIsD3-"
      },
      "source": [
        "##Defining Gradient Update Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1WOa5tAHH_K6"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return\n",
        "\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT9NVg0KsJrO"
      },
      "source": [
        "##Defining a mini-batch generation iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_qWdoUGeID3R"
      },
      "outputs": [],
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1] \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlPAd_JwHJTb"
      },
      "source": [
        "[Problem 1] Creating a one-dimensional convolutional layer class with a limited number of channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ue9veoPwmYtl"
      },
      "outputs": [],
      "source": [
        "class SimpleConv1d():\n",
        "    def forward(self, x, w, b):\n",
        "        a = []\n",
        "        for i in range(len(w) - 1):\n",
        "            a.append((x[i:i+len(w)] @ w) + b[0])\n",
        "        return np.array(a)\n",
        "    def backward(self, x, w, da):\n",
        "        db = np.sum(da)\n",
        "        dw = []\n",
        "        for i in range(len(w)):\n",
        "            dw.append(da @ x[i:i+len(da)])\n",
        "        dw = np.array(dw)\n",
        "        dx = []\n",
        "        new_w = np.insert(w[::-1], 0, 0)\n",
        "        new_w = np.append(new_w, 0)\n",
        "        for i in range(len(new_w)-1):\n",
        "            dx.append(new_w[i:i+len(da)] @ da)\n",
        "        dx = np.array(dx[::-1])\n",
        "        return db, dw, dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAT6Wn2esnMF"
      },
      "source": [
        "[Problem 2] Calculation of output size after one-dimensional convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AUWrp9gsmP1",
        "outputId": "ebe3a3f4-64f2-4785-89b4-db0b991e0bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output: 2\n"
          ]
        }
      ],
      "source": [
        "def output_size_calculation( n_in, filter_size, padding=0, stride=1):\n",
        "        n_out = int((n_in + 2*padding - filter_size) / stride + 1)   \n",
        "        return n_out\n",
        "\n",
        "a = output_size_calculation(4,3,0,1)\n",
        "print(\"output:\", a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDl1Q4DPIdxo"
      },
      "source": [
        "[Problem 3] One-dimensional convolutional layer experiment with small arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-HEc3JNWmZcG"
      },
      "outputs": [],
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBX8OG7oncjU",
        "outputId": "1543b3c4-271d-468c-ea63-e0d185ffd8d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([35, 50])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_conv_1d = SimpleConv1d()\n",
        "simple_conv_1d.forward(x, w, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCKGm0ZXpGgg",
        "outputId": "d044f04d-bf90-4772-d15f-97a9c0f25a2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([35, 50])\n",
        "a_actual = np.array([45, 70])\n",
        "da = np.array([10, 20])\n",
        "db, dw, dx = simple_conv_1d.backward(x, w, da)\n",
        "db, dw, dx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM1fIwMHpzO4",
        "outputId": "e214cc13-1fda-4a14-cb30-00763c34cc35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-60-ea6940f01016>:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
            "<ipython-input-60-ea6940f01016>:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  indexes1 = np.array([1, 2, 3]).astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "\n",
        "a = np.empty((2, 3))\n",
        "\n",
        "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
        "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
        "\n",
        "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
        "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
        "\n",
        "a = a.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL0ax8aQp1pS",
        "outputId": "516dee2a-9611-4c61-ed9d-49e2d6657eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [2 3 4]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-9fe1ed53ac3b>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3, 4])\n",
        "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
        "\n",
        "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_klCDXsIwu6"
      },
      "source": [
        "[Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "_EQG_Qyewkey"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
        "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
        "b = np.array([1, 2, 3]) # （出力チャンネル数）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdQwBZMws1i",
        "outputId": "e45b6ba2-6a18-4bb1-e146-a15ba902ac01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "print forward prop: [[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ]
        }
      ],
      "source": [
        "a = np.zeros([3, output_size_calculation(4,3,0,1)])\n",
        "\n",
        "for och in range(w.shape[0]):\n",
        "    for ch in range(w.shape[1]):\n",
        "        for m in range(a.shape[1]):\n",
        "            a[och,m] += np.sum(x[ch, m:m+w.shape[2]]* w[och,ch,:])\n",
        "\n",
        "a += b[:,None]\n",
        "print(\"print forward prop:\", a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hie3kJ64vr2X",
        "outputId": "341feaf5-1f42-4400-9151-ada1d91a061a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output: 2\n"
          ]
        }
      ],
      "source": [
        "class Conv1d:\n",
        "    def __init__(self, b_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0):\n",
        "        self.b_size = b_size\n",
        "        self.optimizer = AdaGrad\n",
        "        self.Initializer = XavierInitializer\n",
        "        self.pa = pa\n",
        "        self.W = initializer.W(n_out_channels, n_in_channels, b_size)\n",
        "        self.B = initializer.B(n_out_channels)\n",
        "        self.n_in_channels = n_in_channels\n",
        "        self.n_out_channels = n_out_channels\n",
        "        self.n_out = None\n",
        "    def forward(self, X):\n",
        "        self.n_samples = X.shape[0]\n",
        "        self.n_in = X.shape[-1]\n",
        "        self.n_out = output_size_calculation(self.n_in, self.b_size, self.pa, self.stride)\n",
        "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
        "        self.X = np.pad(X, ((0,0), (0,0), ((self.b_size-1), 0)))\n",
        "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.b_size, self.n_in+(self.b_size-1)))\n",
        "        for i in range(self.b_size):\n",
        "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
        "        A = np.sum(self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride]*self.W[:, :, :, np.newaxis], axis=(2, 3)) + self.B.reshape(-1,1)\n",
        "        return A\n",
        "    def backward(self, dA):\n",
        "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride], axis=(0, -1))\n",
        "        self.dB = np.sum(dA, axis=(0, -1))\n",
        "        self.dA = np.pad(dA, ((0,0), (0,0), (0, (self.b_size-1))))\n",
        "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.b_size, self.dA.shape[-1]))\n",
        "        for i in range(self.b_size):\n",
        "            self.dA1[:, :, i] = np.roll(self.dA, i, axis=-1)\n",
        "        dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1,3))\n",
        "        self.optimizer.update(self)\n",
        "        return dX\n",
        "    def output_size_calculation( n_in, filter_size, padding=0, stride=1):\n",
        "            n_out = int((n_in + 2*padding - filter_size) / stride + 1)   \n",
        "            return n_out\n",
        "\n",
        "    a = output_size_calculation(4,3,0,1)\n",
        "    print(\"output:\", a)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNJUQdPDbeZgSSOoiOo/5aB",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
